{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watertight STL to Node Converter\n",
    "Convert tetrahedral meshes in stl format into [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) node representation using the [Trimesh](https://trimesh.org/) library. The converter does not work on non-watertight surfaces, i.e. raw_cloud and raw_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import trimesh\n",
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (5.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-magic in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (0.4.27)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-magic-bin in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (0.4.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-magic\n",
    "%pip install python-magic-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File type for rawnorm: application/zip\n",
      "File type for repaired: application/octet-stream\n"
     ]
    }
   ],
   "source": [
    "import magic\n",
    "file_path = '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/raw/rawnorm/0b4f5b9e-8e94-4107-94bf-3c85494ba2e5.stl'\n",
    "file_type = magic.Magic(mime=True).from_file(file_path)\n",
    "print(f\"File type for rawnorm: {file_type}\")\n",
    "\n",
    "\n",
    "file_path = '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/repaired_files/0a7ab8b4-ab18-4524-b8e7-e773ebc6b268.stl00-1.stl'\n",
    "file_type = magic.Magic(mime=True).from_file(file_path)\n",
    "print(f\"File type for repaired: {file_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to /Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "file_path = '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/raw/rawnorm/0b4f5b9e-8e94-4107-94bf-3c85494ba2e5.stl'\n",
    "extract_dir = '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/'\n",
    "\n",
    "# Extract the ZIP file\n",
    "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(f\"Files extracted to {extract_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting: /Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/.DS_Store\n",
      "File type: application/octet-stream\n",
      "Error reading pickle file: invalid load key, '\\x00'.\n",
      "--------------------------------------------------\n",
      "Inspecting: /Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0b4f5b9e-8e94-4107-94bf-3c85494ba2e5/version\n",
      "File type: text/plain\n",
      "Content (first 500 chars): 3\n",
      "\n",
      "--------------------------------------------------\n",
      "Inspecting: /Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0b4f5b9e-8e94-4107-94bf-3c85494ba2e5/data.pkl\n",
      "File type: application/octet-stream\n",
      "Error reading pickle file: A load persistent id instruction was encountered,\n",
      "but no persistent_load function was specified.\n",
      "--------------------------------------------------\n",
      "Inspecting: /Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0b4f5b9e-8e94-4107-94bf-3c85494ba2e5/data/0\n",
      "File type: application/octet-stream\n",
      "Error reading pickle file: invalid load key, '\\x00'.\n",
      "--------------------------------------------------\n",
      "Inspecting: /Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0b4f5b9e-8e94-4107-94bf-3c85494ba2e5/data/1\n",
      "File type: application/octet-stream\n",
      "Error reading pickle file: invalid load key, '\\x00'.\n",
      "--------------------------------------------------\n",
      "Inspecting: /Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0a7ab8b4-ab18-4524-b8e7-e773ebc6b268.stl0-10/version\n",
      "File type: text/plain\n",
      "Content (first 500 chars): 3\n",
      "\n",
      "--------------------------------------------------\n",
      "Inspecting: /Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0a7ab8b4-ab18-4524-b8e7-e773ebc6b268.stl0-10/data.pkl\n",
      "File type: application/octet-stream\n",
      "Error reading pickle file: A load persistent id instruction was encountered,\n",
      "but no persistent_load function was specified.\n",
      "--------------------------------------------------\n",
      "Inspecting: /Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0a7ab8b4-ab18-4524-b8e7-e773ebc6b268.stl0-10/data/0\n",
      "File type: application/octet-stream\n",
      "Error reading pickle file: invalid load key, '\\x00'.\n",
      "--------------------------------------------------\n",
      "Inspecting: /Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0a7ab8b4-ab18-4524-b8e7-e773ebc6b268.stl0-10/data/1\n",
      "File type: application/octet-stream\n",
      "Error reading pickle file: invalid load key, '\\x00'.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import magic\n",
    "import pickle\n",
    "\n",
    "# Path to the unzipped directory\n",
    "base_dir = '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/'\n",
    "\n",
    "# Function to inspect files\n",
    "def inspect_file(file_path):\n",
    "    print(f\"Inspecting: {file_path}\")\n",
    "    \n",
    "    # Check file type using libmagic\n",
    "    file_type = magic.Magic(mime=True).from_file(file_path)\n",
    "    print(f\"File type: {file_type}\")\n",
    "    \n",
    "    # Handle file based on type\n",
    "    if file_type == 'text/plain':\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                print(f\"Content (first 500 chars): {f.read(500)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading text file: {e}\")\n",
    "    elif file_type == 'application/octet-stream':\n",
    "        try:\n",
    "            # Attempt to load as pickle\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            print(f\"Pickle file loaded successfully. Data type: {type(data)}\")\n",
    "            print(f\"Data preview: {str(data)[:500]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading pickle file: {e}\")\n",
    "    else:\n",
    "        print(f\"Unhandled file type. File type: {file_type}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Walk through the directory and inspect files\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        inspect_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading with PyTorch: A load persistent id instruction was encountered,\n",
      "but no persistent_load function was specified.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "file_path = '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0a7ab8b4-ab18-4524-b8e7-e773ebc6b268.stl0-10/data.pkl'\n",
    "\n",
    "try:\n",
    "    data = torch.load(file_path)\n",
    "    print(f\"Loaded PyTorch data: {type(data)}\")\n",
    "    print(data)  # Be cautious if the data is large\n",
    "except Exception as e:\n",
    "    print(f\"Error loading with PyTorch: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistent load called with: ('storage', <class 'torch.DoubleStorage'>, '0', 'cpu', 3584)\n",
      "Error during manual unpickling: 'NoneType' object has no attribute 'dtype'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0a7ab8b4-ab18-4524-b8e7-e773ebc6b268.stl0-10/data.pkl'\n",
    "\n",
    "def persistent_load(obj):\n",
    "    print(f\"Persistent load called with: {obj}\")\n",
    "    return None  # Stub implementation; real code depends on the context\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        unpickler = pickle.Unpickler(f)\n",
    "        unpickler.persistent_load = persistent_load\n",
    "        data = unpickler.load()\n",
    "        print(f\"Pickle data loaded: {data}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during manual unpickling: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during PyTorch loading: 'persistent_load' is an invalid keyword argument for load()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def persistent_load_debug(obj):\n",
    "    print(f\"Persistent load called with: {obj}\")\n",
    "    return None  # Stub implementation\n",
    "\n",
    "file_path = '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0a7ab8b4-ab18-4524-b8e7-e773ebc6b268.stl0-10/data.pkl'\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = torch.load(f, map_location='cpu', persistent_load=persistent_load_debug)\n",
    "        print(f\"Data loaded successfully: {data}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during PyTorch loading: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy-stl\n",
      "  Downloading numpy_stl-3.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (from numpy-stl) (1.24.4)\n",
      "Collecting python-utils>=3.4.5 (from numpy-stl)\n",
      "  Downloading python_utils-3.9.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: typing-extensions>3.10.0.2 in /opt/miniconda3/envs/fea-env/lib/python3.9/site-packages (from python-utils>=3.4.5->numpy-stl) (4.12.2)\n",
      "Downloading numpy_stl-3.1.2-py3-none-any.whl (20 kB)\n",
      "Downloading python_utils-3.9.0-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: python-utils, numpy-stl\n",
      "Successfully installed numpy-stl-3.1.2 python-utils-3.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy-stl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistent load called with: ('storage', <class 'torch.DoubleStorage'>, '0', 'cpu', 3584)\n",
      "Persistent load called with: ('storage', <class 'torch.DoubleStorage'>, '1', 'cpu', 512)\n",
      "\n",
      "--- Successfully Loaded .pkl File ---\n",
      "Data Type: <class 'tuple'>\n",
      "Length of Tuple: 2\n",
      "Element 0: Type: <class 'torch.Tensor'>, Shape: torch.Size([512, 7])\n",
      "Element 1: Type: <class 'torch.Tensor'>, Shape: torch.Size([512])\n",
      "\n",
      "--- Inspecting Other Files in the Same Directory ---\n",
      "File: version, Size: 2 bytes\n",
      "File: data.pkl, Size: 211 bytes\n",
      "File: data, Size: 128 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Path to the .pkl file and its directory\n",
    "file_path = '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0b4f5b9e-8e94-4107-94bf-3c85494ba2e5/data.pkl'\n",
    "directory = os.path.dirname(file_path)\n",
    "\n",
    "# Persistent load function for unpickling\n",
    "def persistent_load(obj):\n",
    "    print(f\"Persistent load called with: {obj}\")\n",
    "    if isinstance(obj, tuple) and obj[0] == 'storage':\n",
    "        storage_type, _, device, size = obj[1:]\n",
    "        if storage_type == torch.DoubleStorage:\n",
    "            return torch.empty(size, dtype=torch.float64, device=device).storage()\n",
    "    raise pickle.UnpicklingError(f\"Unknown persistent_load object: {obj}\")\n",
    "\n",
    "# Load and inspect the .pkl file\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        unpickler = pickle.Unpickler(f)\n",
    "        unpickler.persistent_load = persistent_load\n",
    "        data = unpickler.load()\n",
    "        print(\"\\n--- Successfully Loaded .pkl File ---\")\n",
    "        print(f\"Data Type: {type(data)}\")\n",
    "        if isinstance(data, dict):\n",
    "            print(f\"Keys in Dictionary: {data.keys()}\")\n",
    "        elif isinstance(data, list):\n",
    "            print(f\"Length of List: {len(data)}\")\n",
    "        elif isinstance(data, tuple):\n",
    "            print(f\"Length of Tuple: {len(data)}\")\n",
    "            for i, element in enumerate(data):\n",
    "                print(f\"Element {i}: Type: {type(element)}, Shape: {getattr(element, 'shape', 'N/A')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading .pkl file: {e}\")\n",
    "\n",
    "# Inspect files in the same directory\n",
    "print(\"\\n--- Inspecting Other Files in the Same Directory ---\")\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    print(f\"File: {filename}, Size: {os.path.getsize(file_path)} bytes\")\n",
    "    # If the file is another .pkl, try inspecting it\n",
    "    if filename.endswith('.pkl') and filename != os.path.basename(file_path):\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                other_data = pickle.load(f)\n",
    "                print(f\"  - {filename}: Successfully loaded (Type: {type(other_data)})\")\n",
    "                if isinstance(other_data, dict):\n",
    "                    print(f\"    Keys: {other_data.keys()}\")\n",
    "                elif isinstance(other_data, list):\n",
    "                    print(f\"    Length: {len(other_data)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - {filename}: Error loading file ({e})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inspecting Other Files in the Directory ---\n",
      "\n",
      "File: version, Size: 2 bytes\n",
      "File Type: text/plain\n",
      "Text Content of version:\n",
      "3\n",
      "\n",
      "\n",
      "File: data.pkl, Size: 211 bytes\n",
      "File Type: application/octet-stream\n",
      "Error unpickling file data.pkl: A load persistent id instruction was encountered,\n",
      "but no persistent_load function was specified.\n",
      "\n",
      "File: data, Size: 128 bytes\n",
      "Error determining file type: [Errno 21] Is a directory: '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0b4f5b9e-8e94-4107-94bf-3c85494ba2e5/data'\n",
      "Skipping unsupported or binary file: data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import magic\n",
    "\n",
    "# Directory path\n",
    "directory = '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0b4f5b9e-8e94-4107-94bf-3c85494ba2e5'\n",
    "\n",
    "# Inspect each file in the directory\n",
    "print(\"\\n--- Inspecting Other Files in the Directory ---\")\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    print(f\"\\nFile: {filename}, Size: {file_size} bytes\")\n",
    "\n",
    "    # Use magic to determine file type\n",
    "    try:\n",
    "        mime = magic.Magic(mime=True)\n",
    "        file_type = mime.from_file(file_path)\n",
    "        print(f\"File Type: {file_type}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error determining file type: {e}\")\n",
    "        file_type = None\n",
    "\n",
    "    # Attempt to open .pkl files\n",
    "    if filename.endswith('.pkl'):\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                content = pickle.load(f)\n",
    "                print(f\"Successfully unpickled {filename}.\")\n",
    "                print(f\"Type of content: {type(content)}\")\n",
    "                if isinstance(content, dict):\n",
    "                    print(f\"Keys in dictionary: {content.keys()}\")\n",
    "                elif isinstance(content, list):\n",
    "                    print(f\"List length: {len(content)}\")\n",
    "                elif isinstance(content, tuple):\n",
    "                    print(f\"Tuple length: {len(content)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error unpickling file {filename}: {e}\")\n",
    "\n",
    "    # Attempt to read text files\n",
    "    elif file_type and \"text\" in file_type:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                content = f.read()\n",
    "                print(f\"Text Content of {filename}:\\n{content[:500]}\")  # Limit to first 500 chars\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading text file {filename}: {e}\")\n",
    "\n",
    "    # Log if the file type is unsupported\n",
    "    else:\n",
    "        print(f\"Skipping unsupported or binary file: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 1: Loading Main data.pkl ---\n",
      "Persistent load called with: ('storage', <class 'torch.DoubleStorage'>, '0', 'cpu', 3584)\n",
      "Persistent load called with: ('storage', <class 'torch.DoubleStorage'>, '1', 'cpu', 512)\n",
      "\n",
      "--- Successfully Loaded Main data.pkl ---\n",
      "Data Type: <class 'tuple'>\n",
      "Tuple Length: 2\n",
      "\n",
      "--- Step 2: Inspecting Additional data.pkl ---\n",
      "Persistent load called with: ('storage', <class 'torch.DoubleStorage'>, '0', 'cpu', 3584)\n",
      "Persistent load called with: ('storage', <class 'torch.DoubleStorage'>, '1', 'cpu', 512)\n",
      "\n",
      "--- Successfully Loaded data.pkl ---\n",
      "Data Type: <class 'tuple'>\n",
      "Tuple Length: 2\n",
      "\n",
      "--- Step 3: Inspecting Contents of the 'data' Directory ---\n",
      "\n",
      "File: 0, Size: 28672 bytes\n",
      "File Type: application/octet-stream\n",
      "\n",
      "File: 1, Size: 4096 bytes\n",
      "File Type: application/octet-stream\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import magic\n",
    "import torch\n",
    "\n",
    "# Paths to the files and directory\n",
    "main_pkl_path = '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0b4f5b9e-8e94-4107-94bf-3c85494ba2e5/data.pkl'\n",
    "data_dir_path = '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0b4f5b9e-8e94-4107-94bf-3c85494ba2e5/data'\n",
    "\n",
    "# Persistent load function for unpickling\n",
    "def persistent_load(obj):\n",
    "    print(f\"Persistent load called with: {obj}\")\n",
    "    if isinstance(obj, tuple) and obj[0] == 'storage':\n",
    "        storage_type, _, device, size = obj[1:]\n",
    "        if storage_type == torch.DoubleStorage:\n",
    "            return torch.empty(size, dtype=torch.float64, device=device).storage()\n",
    "    raise pickle.UnpicklingError(f\"Unknown persistent_load object: {obj}\")\n",
    "\n",
    "# Step 1: Load and inspect main data.pkl\n",
    "print(\"\\n--- Step 1: Loading Main data.pkl ---\")\n",
    "try:\n",
    "    with open(main_pkl_path, 'rb') as f:\n",
    "        unpickler = pickle.Unpickler(f)\n",
    "        unpickler.persistent_load = persistent_load\n",
    "        main_data = unpickler.load()\n",
    "        print(\"\\n--- Successfully Loaded Main data.pkl ---\")\n",
    "        print(f\"Data Type: {type(main_data)}\")\n",
    "        if isinstance(main_data, dict):\n",
    "            print(f\"Keys: {main_data.keys()}\")\n",
    "        elif isinstance(main_data, tuple):\n",
    "            print(f\"Tuple Length: {len(main_data)}\")\n",
    "        elif isinstance(main_data, list):\n",
    "            print(f\"List Length: {len(main_data)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading main data.pkl: {e}\")\n",
    "\n",
    "# Step 2: Inspect the 'data.pkl' file in the same directory\n",
    "print(\"\\n--- Step 2: Inspecting Additional data.pkl ---\")\n",
    "try:\n",
    "    with open(main_pkl_path, 'rb') as f:\n",
    "        unpickler = pickle.Unpickler(f)\n",
    "        unpickler.persistent_load = persistent_load\n",
    "        data_pkl_content = unpickler.load()\n",
    "        print(\"\\n--- Successfully Loaded data.pkl ---\")\n",
    "        print(f\"Data Type: {type(data_pkl_content)}\")\n",
    "        if isinstance(data_pkl_content, dict):\n",
    "            print(f\"Keys: {data_pkl_content.keys()}\")\n",
    "        elif isinstance(data_pkl_content, tuple):\n",
    "            print(f\"Tuple Length: {len(data_pkl_content)}\")\n",
    "        elif isinstance(data_pkl_content, list):\n",
    "            print(f\"List Length: {len(data_pkl_content)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading additional data.pkl: {e}\")\n",
    "\n",
    "# Step 3: Inspect the 'data' directory and its contents\n",
    "print(\"\\n--- Step 3: Inspecting Contents of the 'data' Directory ---\")\n",
    "try:\n",
    "    for filename in os.listdir(data_dir_path):\n",
    "        file_path = os.path.join(data_dir_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            print(f\"\\nFile: {filename}, Size: {os.path.getsize(file_path)} bytes\")\n",
    "            try:\n",
    "                # Determine file type using python-magic\n",
    "                mime = magic.Magic(mime=True)\n",
    "                file_type = mime.from_file(file_path)\n",
    "                print(f\"File Type: {file_type}\")\n",
    "\n",
    "                # If it's a pickle file, try to unpickle it\n",
    "                if filename.endswith('.pkl'):\n",
    "                    try:\n",
    "                        with open(file_path, 'rb') as f:\n",
    "                            content = pickle.load(f)\n",
    "                            print(f\"Successfully unpickled {filename}.\")\n",
    "                            print(f\"Type of content: {type(content)}\")\n",
    "                            if isinstance(content, dict):\n",
    "                                print(f\"Keys: {content.keys()}\")\n",
    "                            elif isinstance(content, tuple):\n",
    "                                print(f\"Tuple Length: {len(content)}\")\n",
    "                            elif isinstance(content, list):\n",
    "                                print(f\"List Length: {len(content)}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error unpickling file {filename}: {e}\")\n",
    "                # If it's a text file, read the content\n",
    "                elif \"text\" in file_type:\n",
    "                    try:\n",
    "                        with open(file_path, 'r') as f:\n",
    "                            print(f\"Text Content of {filename}:\\n{f.read()[:500]}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading text file {filename}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error determining file type for {filename}: {e}\")\n",
    "        elif os.path.isdir(file_path):\n",
    "            print(f\"Directory: {filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inspecting files in 'data' directory: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inspecting Octet-Stream Binary Files ---\n",
      "\n",
      "File: 0, Size: 28672 bytes\n",
      "File Type Detected: application/octet-stream\n",
      "Error unpickling file 0: invalid load key, '\\x00'.\n",
      "Hex Preview: 00000040d9a4febfabaaaaaa5347db3f000000c0f3efc63f000000000000f0bf0000000000000000000000000000000000807f3832f1df3f00000040d9a4febf\n",
      "ASCII Preview: \u0000\u0000\u0000@٤������SG�?\u0000\u0000\u0000����?\u0000\u0000\u0000\u0000\u0000\u0000�\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000�82��?\u0000\u0000\u0000@٤��\n",
      "\n",
      "File: 1, Size: 4096 bytes\n",
      "File Type Detected: application/octet-stream\n",
      "Error unpickling file 1: invalid load key, '\\x00'.\n",
      "Hex Preview: 00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "ASCII Preview: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "# Paths to binary files\n",
    "binary_files = [\n",
    "    os.path.join(data_dir_path, '0'),\n",
    "    os.path.join(data_dir_path, '1'),\n",
    "]\n",
    "\n",
    "print(\"\\n--- Inspecting Octet-Stream Binary Files ---\")\n",
    "for file_path in binary_files:\n",
    "    print(f\"\\nFile: {os.path.basename(file_path)}, Size: {os.path.getsize(file_path)} bytes\")\n",
    "\n",
    "    # Attempt to detect file format with magic\n",
    "    try:\n",
    "        file_type = magic.Magic(mime=True).from_file(file_path)\n",
    "        print(f\"File Type Detected: {file_type}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting file type: {e}\")\n",
    "\n",
    "    # Try opening as a pickle file\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            content = pickle.load(f)\n",
    "            print(f\"Successfully unpickled {os.path.basename(file_path)}.\")\n",
    "            print(f\"Type of content: {type(content)}\")\n",
    "            if isinstance(content, dict):\n",
    "                print(f\"Keys: {content.keys()}\")\n",
    "            elif isinstance(content, tuple):\n",
    "                print(f\"Tuple Length: {len(content)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error unpickling file {os.path.basename(file_path)}: {e}\")\n",
    "\n",
    "    # Try reading first 64 bytes for hex/ASCII preview\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            preview = f.read(64)\n",
    "            print(\"Hex Preview:\", preview.hex())\n",
    "            print(\"ASCII Preview:\", preview.decode(errors='replace'))\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {os.path.basename(file_path)}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing if File is an STL ---\n",
      "Successfully loaded as STL with numpy-stl.\n",
      "Number of triangles: 0\n",
      "Error loading with trimesh: decode() argument 'encoding' must be str, not None\n"
     ]
    }
   ],
   "source": [
    "from stl import mesh\n",
    "import trimesh\n",
    "\n",
    "# Path to the file\n",
    "file_path = '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0b4f5b9e-8e94-4107-94bf-3c85494ba2e5/data/0'\n",
    "\n",
    "print(\"\\n--- Testing if File is an STL ---\")\n",
    "\n",
    "# Test with numpy-stl\n",
    "try:\n",
    "    your_mesh = mesh.Mesh.from_file(file_path)\n",
    "    print(\"Successfully loaded as STL with numpy-stl.\")\n",
    "    print(f\"Number of triangles: {len(your_mesh)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading with numpy-stl: {e}\")\n",
    "\n",
    "# Test with trimesh\n",
    "try:\n",
    "    trimesh_mesh = trimesh.load(file_path, file_type='stl')\n",
    "    print(\"Successfully loaded as STL with trimesh.\")\n",
    "    print(f\"Vertices: {len(trimesh_mesh.vertices)}, Faces: {len(trimesh_mesh.faces)}\")\n",
    "    trimesh_mesh.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading with trimesh: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 1: Attempting to Load with numpy-stl ---\n",
      "Successfully loaded as STL with numpy-stl.\n",
      "Number of triangles: 0\n",
      "The STL file appears to be empty (no triangles).\n",
      "\n",
      "--- Step 2: Reading STL Header ---\n",
      "--- STL Header ---\n",
      "\u0000\u0000\u0000@٤������SG�?\u0000\u0000\u0000����?\u0000\u0000\u0000\u0000\u0000\u0000�\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000�82��?\u0000\u0000\u0000@٤������\u0018i�?\u0000\u0000\u0000����?\n",
      "Hex: 00000040d9a4febfabaaaaaa5347db3f000000c0f3efc63f000000000000f0bf0000000000000000000000000000000000807f3832f1df3f00000040d9a4febfabaaaaea1869f83f000000e080f9d03f\n",
      "\n",
      "--- Step 3: Attempting to Load with trimesh ---\n",
      "Error loading with trimesh: decode() argument 'encoding' must be str, not None\n"
     ]
    }
   ],
   "source": [
    "from stl import mesh\n",
    "import trimesh\n",
    "\n",
    "# Path to the binary file\n",
    "file_path = '/Users/rgopalam/Desktop/URAP-GNN/additivemodels/data/unzipped/0b4f5b9e-8e94-4107-94bf-3c85494ba2e5/data/0'\n",
    "\n",
    "print(\"\\n--- Step 1: Attempting to Load with numpy-stl ---\")\n",
    "# Test with numpy-stl and inspect data\n",
    "try:\n",
    "    your_mesh = mesh.Mesh.from_file(file_path)\n",
    "    print(\"Successfully loaded as STL with numpy-stl.\")\n",
    "    print(f\"Number of triangles: {len(your_mesh)}\")\n",
    "    if len(your_mesh) > 0:\n",
    "        print(\"Triangle Data Preview:\")\n",
    "        print(your_mesh.vectors[:5])  # Print the first 5 triangle vectors\n",
    "    else:\n",
    "        print(\"The STL file appears to be empty (no triangles).\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading with numpy-stl: {e}\")\n",
    "\n",
    "print(\"\\n--- Step 2: Reading STL Header ---\")\n",
    "# Read the first 80 bytes of the binary file (STL header)\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        header = f.read(80)\n",
    "        print(\"--- STL Header ---\")\n",
    "        print(header.decode(errors='replace'))  # Decode as text (replace invalid characters)\n",
    "        print(\"Hex:\", header.hex())  # Display hex representation of the header\n",
    "except Exception as e:\n",
    "    print(f\"Error reading STL header: {e}\")\n",
    "\n",
    "print(\"\\n--- Step 3: Attempting to Load with trimesh ---\")\n",
    "# Test with trimesh\n",
    "try:\n",
    "    trimesh_mesh = trimesh.load(file_path, file_type='stl', encoding='binary')  # Force binary format\n",
    "    print(\"Successfully loaded as STL with trimesh.\")\n",
    "    print(f\"Vertices: {len(trimesh_mesh.vertices)}, Faces: {len(trimesh_mesh.faces)}\")\n",
    "    if len(trimesh_mesh.vertices) > 0 and len(trimesh_mesh.faces) > 0:\n",
    "        print(\"Displaying mesh using trimesh...\")\n",
    "        trimesh_mesh.show()\n",
    "    else:\n",
    "        print(\"The STL file contains no valid geometry.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading with trimesh: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fea-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
